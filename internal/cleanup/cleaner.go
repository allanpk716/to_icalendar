package cleanup

import (
	"fmt"
	"log"
	"os"
	"path/filepath"
	"strings"
	"time"

	"github.com/allanpk716/to_icalendar/internal/config"
	"github.com/allanpk716/to_icalendar/internal/deduplication"
	"github.com/allanpk716/to_icalendar/internal/image"
)

// Cleaner æ¸…ç†å™¨ç»“æ„
type Cleaner struct {
	configManager *config.ConfigManager
	cacheManager  *deduplication.CacheManager
	imageConfig   *image.ConfigManager
	logger        *log.Logger
}

// CleanOptions æ¸…ç†é€‰é¡¹
type CleanOptions struct {
	All           bool   // æ¸…ç†æ‰€æœ‰ç¼“å­˜
	Tasks         bool   // æ¸…ç†ä»»åŠ¡ç¼“å­˜
	Images        bool   // æ¸…ç†å›¾ç‰‡ç¼“å­˜
	ImageHashes   bool   // æ¸…ç†å›¾ç‰‡å“ˆå¸Œç¼“å­˜
	Temp          bool   // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
	Generated     bool   // æ¸…ç†ç”Ÿæˆçš„JSONæ–‡ä»¶
	DryRun        bool   // é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…åˆ é™¤
	Force         bool   // å¼ºåˆ¶æ¸…ç†ï¼Œè·³è¿‡ç¡®è®¤
	OlderThan     string // æ—¶é—´è¿‡æ»¤ï¼Œå¦‚ "7d", "24h"
	ClearAll      bool   // å®Œå…¨æ¸…ç©ºæ‰€æœ‰ç¼“å­˜æ•°æ®
}

// CleanResult æ¸…ç†ç»“æœ
type CleanResult struct {
	CacheType    string    // ç¼“å­˜ç±»å‹
	FilesCount   int       // åˆ é™¤çš„æ–‡ä»¶æ•°é‡
	SizeBytes    int64     // åˆ é™¤çš„æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
	Files        []string  // åˆ é™¤çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆé¢„è§ˆæ¨¡å¼ä¸‹ä½¿ç”¨ï¼‰
	Duration     time.Duration // æ¸…ç†è€—æ—¶
	Error        error     // é”™è¯¯ä¿¡æ¯
}

// NewCleaner åˆ›å»ºæ–°çš„æ¸…ç†å™¨
func NewCleaner() *Cleaner {
	return &Cleaner{
		logger: log.Default(),
	}
}

// SetConfig è®¾ç½®é…ç½®ç®¡ç†å™¨
func (c *Cleaner) SetConfig(configManager *config.ConfigManager) {
	c.configManager = configManager
}

// SetCacheManager è®¾ç½®ç¼“å­˜ç®¡ç†å™¨
func (c *Cleaner) SetCacheManager(cacheManager *deduplication.CacheManager) {
	c.cacheManager = cacheManager
}

// SetImageConfig è®¾ç½®å›¾ç‰‡é…ç½®
func (c *Cleaner) SetImageConfig(imageConfig *image.ConfigManager) {
	c.imageConfig = imageConfig
}

// Clean æ‰§è¡Œæ¸…ç†æ“ä½œ
func (c *Cleaner) Clean(options CleanOptions) (*CleanSummary, error) {
	startTime := time.Now()
	summary := &CleanSummary{
		Results: make([]CleanResult, 0),
	}

	// è§£ææ—¶é—´è¿‡æ»¤æ¡ä»¶
	olderThanTime, err := c.parseOlderThan(options.OlderThan)
	if err != nil {
		return nil, fmt.Errorf("è§£ææ—¶é—´å‚æ•°å¤±è´¥: %v", err)
	}

	// æ ¹æ®é€‰é¡¹æ‰§è¡Œç›¸åº”çš„æ¸…ç†æ“ä½œ
	if options.All || options.Tasks {
		result := c.cleanTasksCache(options.DryRun, olderThanTime)
		summary.Results = append(summary.Results, result)
	}

	if options.All || options.Images || options.ImageHashes {
		result := c.cleanImagesCache(options.DryRun, olderThanTime)
		summary.Results = append(summary.Results, result)
	}

	if options.ImageHashes {
		result := c.cleanImageHashCache(options.DryRun)
		summary.Results = append(summary.Results, result)
	}

	if options.All || options.Temp {
		result := c.cleanTempFiles(options.DryRun, olderThanTime)
		summary.Results = append(summary.Results, result)
	}

	if options.All || options.Generated {
		result := c.cleanGeneratedFiles(options.DryRun, olderThanTime)
		summary.Results = append(summary.Results, result)
	}

	// å¦‚æœè®¾ç½®äº†å®Œå…¨æ¸…ç©ºé€‰é¡¹
	if options.ClearAll && c.cacheManager != nil && !options.DryRun {
		if err := c.cacheManager.ClearCache(); err != nil {
			c.logger.Printf("æ¸…ç©ºæ‰€æœ‰ç¼“å­˜å¤±è´¥: %v", err)
		} else {
			c.logger.Printf("å·²æ¸…ç©ºæ‰€æœ‰ç¼“å­˜æ•°æ®")
		}
	}

	summary.Duration = time.Since(startTime)
	summary.TotalFiles = summary.getTotalFiles()
	summary.TotalSize = summary.getTotalSize()

	return summary, nil
}

// CleanSummary æ¸…ç†æ‘˜è¦
type CleanSummary struct {
	Results    []CleanResult  // æ¸…ç†ç»“æœåˆ—è¡¨
	Duration   time.Duration  // æ€»è€—æ—¶
	TotalFiles int            // æ€»æ–‡ä»¶æ•°
	TotalSize  int64          // æ€»å¤§å°ï¼ˆå­—èŠ‚ï¼‰
}

// getTotalFiles è®¡ç®—æ€»æ–‡ä»¶æ•°
func (s *CleanSummary) getTotalFiles() int {
	total := 0
	for _, result := range s.Results {
		total += result.FilesCount
	}
	return total
}

// getTotalSize è®¡ç®—æ€»å¤§å°
func (s *CleanSummary) getTotalSize() int64 {
	var total int64
	for _, result := range s.Results {
		total += result.SizeBytes
	}
	return total
}

// cleanTasksCache æ¸…ç†ä»»åŠ¡ç¼“å­˜
func (c *Cleaner) cleanTasksCache(dryRun bool, olderThanTime time.Time) CleanResult {
	result := CleanResult{
		CacheType: "ä»»åŠ¡ç¼“å­˜",
		Files:     make([]string, 0),
	}

	startTime := time.Now()
	defer func() {
		result.Duration = time.Since(startTime)
	}()

	if c.cacheManager == nil {
		result.Error = fmt.Errorf("ç¼“å­˜ç®¡ç†å™¨æœªåˆå§‹åŒ–")
		return result
	}

	// è·å–ç¼“å­˜ç›®å½•è·¯å¾„
	cacheDir := c.cacheManager.GetCacheDir()
	if cacheDir == "" {
		result.Error = fmt.Errorf("æ— æ³•è·å–ç¼“å­˜ç›®å½•è·¯å¾„")
		return result
	}

	// éå†ç¼“å­˜ç›®å½•
	err := filepath.Walk(cacheDir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		// è·³è¿‡ç›®å½•æœ¬èº«
		if info.IsDir() {
			return nil
		}

		// æ£€æŸ¥æ–‡ä»¶æ—¶é—´
		if !olderThanTime.IsZero() && info.ModTime().After(olderThanTime) {
			return nil
		}

		// æ”¶é›†æ–‡ä»¶ä¿¡æ¯
		result.FilesCount++
		result.SizeBytes += info.Size()
		result.Files = append(result.Files, path)

		// å¦‚æœä¸æ˜¯é¢„è§ˆæ¨¡å¼ï¼Œåˆ™åˆ é™¤æ–‡ä»¶
		if !dryRun {
			if err := os.Remove(path); err != nil {
				result.Error = fmt.Errorf("åˆ é™¤æ–‡ä»¶ %s å¤±è´¥: %v", path, err)
				return err
			}
			c.logger.Printf("å·²åˆ é™¤ä»»åŠ¡ç¼“å­˜æ–‡ä»¶: %s", path)
		}

		return nil
	})

	if err != nil {
		result.Error = fmt.Errorf("æ¸…ç†ä»»åŠ¡ç¼“å­˜å¤±è´¥: %v", err)
	}

	return result
}

// cleanImagesCache æ¸…ç†å›¾ç‰‡ç¼“å­˜
func (c *Cleaner) cleanImagesCache(dryRun bool, olderThanTime time.Time) CleanResult {
	result := CleanResult{
		CacheType: "å›¾ç‰‡ç¼“å­˜",
		Files:     make([]string, 0),
	}

	startTime := time.Now()
	defer func() {
		result.Duration = time.Since(startTime)
	}()

	// 1. æ¸…ç†å›¾ç‰‡æ–‡ä»¶ç¼“å­˜
	cacheDir := c.getImageCacheDir()
	if cacheDir != "" {
		err := filepath.Walk(cacheDir, func(path string, info os.FileInfo, err error) error {
			if err != nil {
				return err
			}

			// è·³è¿‡ç›®å½•æœ¬èº«
			if info.IsDir() {
				return nil
			}

			// åªå¤„ç†å›¾ç‰‡æ–‡ä»¶
			if !c.isImageFile(path) {
				return nil
			}

			// æ£€æŸ¥æ–‡ä»¶æ—¶é—´
			if !olderThanTime.IsZero() && info.ModTime().After(olderThanTime) {
				return nil
			}

			// æ”¶é›†æ–‡ä»¶ä¿¡æ¯
			result.FilesCount++
			result.SizeBytes += info.Size()
			result.Files = append(result.Files, path)

			// å¦‚æœä¸æ˜¯é¢„è§ˆæ¨¡å¼ï¼Œåˆ™åˆ é™¤æ–‡ä»¶
			if !dryRun {
				if err := os.Remove(path); err != nil {
					result.Error = fmt.Errorf("åˆ é™¤å›¾ç‰‡æ–‡ä»¶ %s å¤±è´¥: %v", path, err)
					return err
				}
				c.logger.Printf("å·²åˆ é™¤å›¾ç‰‡ç¼“å­˜æ–‡ä»¶: %s", path)
			}

			return nil
		})

		if err != nil {
			result.Error = fmt.Errorf("æ¸…ç†å›¾ç‰‡æ–‡ä»¶ç¼“å­˜å¤±è´¥: %v", err)
			return result
		}
	}

	// 2. æ¸…ç†å›¾ç‰‡å“ˆå¸Œç¼“å­˜æ–‡ä»¶
	if c.cacheManager != nil {
		cacheDir = c.cacheManager.GetCacheDir()
		if cacheDir != "" {
			imageHashFile := filepath.Join(cacheDir, "image_hashes.json")

			// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
			if info, err := os.Stat(imageHashFile); err == nil {
				// æ£€æŸ¥æ–‡ä»¶æ—¶é—´
				if olderThanTime.IsZero() || info.ModTime().Before(olderThanTime) || dryRun {
					result.FilesCount++
					result.SizeBytes += info.Size()
					result.Files = append(result.Files, imageHashFile)

					// å¦‚æœä¸æ˜¯é¢„è§ˆæ¨¡å¼ï¼Œåˆ™æ¸…ç†å›¾ç‰‡å“ˆå¸Œç¼“å­˜
					if !dryRun {
						// ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨çš„æ¸…ç†æ–¹æ³•ï¼Œè¿™æ ·ä¼šå¤„ç†è¿‡æœŸæ•°æ®
						if err := c.cacheManager.CleanupExpiredImages(); err != nil {
							result.Error = fmt.Errorf("æ¸…ç†å›¾ç‰‡å“ˆå¸Œç¼“å­˜å¤±è´¥: %v", err)
							return result
						}
						c.logger.Printf("å·²æ¸…ç†å›¾ç‰‡å“ˆå¸Œç¼“å­˜: %s", imageHashFile)
					}
				}
			}
		}
	}

	return result
}

// cleanImageHashCache ä¸“é—¨æ¸…ç†å›¾ç‰‡å“ˆå¸Œç¼“å­˜
func (c *Cleaner) cleanImageHashCache(dryRun bool) CleanResult {
	result := CleanResult{
		CacheType: "å›¾ç‰‡å“ˆå¸Œç¼“å­˜",
		Files:     make([]string, 0),
	}

	startTime := time.Now()
	defer func() {
		result.Duration = time.Since(startTime)
	}()

	if c.cacheManager == nil {
		result.Error = fmt.Errorf("ç¼“å­˜ç®¡ç†å™¨æœªåˆå§‹åŒ–")
		return result
	}

	// è·å–ç¼“å­˜ç›®å½•è·¯å¾„
	cacheDir := c.cacheManager.GetCacheDir()
	if cacheDir == "" {
		result.Error = fmt.Errorf("æ— æ³•è·å–ç¼“å­˜ç›®å½•è·¯å¾„")
		return result
	}

	// å›¾ç‰‡å“ˆå¸Œç¼“å­˜æ–‡ä»¶è·¯å¾„
	imageHashFile := filepath.Join(cacheDir, "image_hashes.json")

	// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
	if info, err := os.Stat(imageHashFile); err == nil {
		result.FilesCount++
		result.SizeBytes += info.Size()
		result.Files = append(result.Files, imageHashFile)

		// å¦‚æœä¸æ˜¯é¢„è§ˆæ¨¡å¼ï¼Œåˆ™æ¸…ç©ºå›¾ç‰‡å“ˆå¸Œç¼“å­˜
		if !dryRun {
			if err := c.cacheManager.ClearImageCache(); err != nil {
				result.Error = fmt.Errorf("æ¸…ç©ºå›¾ç‰‡å“ˆå¸Œç¼“å­˜å¤±è´¥: %v", err)
				return result
			}
			c.logger.Printf("å·²æ¸…ç©ºå›¾ç‰‡å“ˆå¸Œç¼“å­˜: %s", imageHashFile)
		}
	} else if os.IsNotExist(err) {
		c.logger.Printf("å›¾ç‰‡å“ˆå¸Œç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: %s", imageHashFile)
	} else {
		result.Error = fmt.Errorf("æ£€æŸ¥å›¾ç‰‡å“ˆå¸Œç¼“å­˜æ–‡ä»¶å¤±è´¥: %v", err)
		return result
	}

	return result
}

// cleanTempFiles æ¸…ç†ä¸´æ—¶æ–‡ä»¶
func (c *Cleaner) cleanTempFiles(dryRun bool, olderThanTime time.Time) CleanResult {
	result := CleanResult{
		CacheType: "ä¸´æ—¶æ–‡ä»¶",
		Files:     make([]string, 0),
	}

	startTime := time.Now()
	defer func() {
		result.Duration = time.Since(startTime)
	}()

	// è·å–ä¸´æ—¶ç›®å½•
	tempDir := c.getTempDir()
	if tempDir == "" {
		result.Error = fmt.Errorf("æ— æ³•è·å–ä¸´æ—¶ç›®å½•è·¯å¾„")
		return result
	}

	// å¦‚æœä¸´æ—¶ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™è·³è¿‡
	if _, err := os.Stat(tempDir); os.IsNotExist(err) {
		return result
	}

	// éå†ä¸´æ—¶ç›®å½•
	err := filepath.Walk(tempDir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		// è·³è¿‡ç›®å½•æœ¬èº«
		if info.IsDir() {
			return nil
		}

		// æ£€æŸ¥æ–‡ä»¶æ—¶é—´
		if !olderThanTime.IsZero() && info.ModTime().After(olderThanTime) {
			return nil
		}

		// æ”¶é›†æ–‡ä»¶ä¿¡æ¯
		result.FilesCount++
		result.SizeBytes += info.Size()
		result.Files = append(result.Files, path)

		// å¦‚æœä¸æ˜¯é¢„è§ˆæ¨¡å¼ï¼Œåˆ™åˆ é™¤æ–‡ä»¶
		if !dryRun {
			if err := os.Remove(path); err != nil {
				result.Error = fmt.Errorf("åˆ é™¤ä¸´æ—¶æ–‡ä»¶ %s å¤±è´¥: %v", path, err)
				return err
			}
			c.logger.Printf("å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: %s", path)
		}

		return nil
	})

	if err != nil {
		result.Error = fmt.Errorf("æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: %v", err)
	}

	return result
}

// cleanGeneratedFiles æ¸…ç†ç”Ÿæˆçš„JSONæ–‡ä»¶
func (c *Cleaner) cleanGeneratedFiles(dryRun bool, olderThanTime time.Time) CleanResult {
	result := CleanResult{
		CacheType: "ç”Ÿæˆæ–‡ä»¶",
		Files:     make([]string, 0),
	}

	startTime := time.Now()
	defer func() {
		result.Duration = time.Since(startTime)
	}()

	// ä½¿ç”¨å½“å‰ç›®å½•ä½œä¸ºè¾“å‡ºç›®å½•
	outputDir := "."

	// éå†è¾“å‡ºç›®å½•ï¼ŒæŸ¥æ‰¾ç”Ÿæˆçš„JSONæ–‡ä»¶
	err := filepath.Walk(outputDir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		// è·³è¿‡ç›®å½•æœ¬èº«å’Œéšè—ç›®å½•
		if info.IsDir() {
			if strings.HasPrefix(filepath.Base(path), ".") || path == "." {
				return nil
			}
			return nil
		}

		// åªå¤„ç†ç”Ÿæˆçš„JSONæ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯ä¸´æ—¶ç”Ÿæˆçš„ï¼‰
		if !c.isGeneratedFile(path) {
			return nil
		}

		// æ£€æŸ¥æ–‡ä»¶æ—¶é—´
		if !olderThanTime.IsZero() && info.ModTime().After(olderThanTime) {
			return nil
		}

		// æ”¶é›†æ–‡ä»¶ä¿¡æ¯
		result.FilesCount++
		result.SizeBytes += info.Size()
		result.Files = append(result.Files, path)

		// å¦‚æœä¸æ˜¯é¢„è§ˆæ¨¡å¼ï¼Œåˆ™åˆ é™¤æ–‡ä»¶
		if !dryRun {
			if err := os.Remove(path); err != nil {
				result.Error = fmt.Errorf("åˆ é™¤ç”Ÿæˆæ–‡ä»¶ %s å¤±è´¥: %v", path, err)
				return err
			}
			c.logger.Printf("å·²åˆ é™¤ç”Ÿæˆæ–‡ä»¶: %s", path)
		}

		return nil
	})

	if err != nil {
		result.Error = fmt.Errorf("æ¸…ç†ç”Ÿæˆæ–‡ä»¶å¤±è´¥: %v", err)
	}

	return result
}

// parseOlderThan è§£ææ—¶é—´è¿‡æ»¤å‚æ•°
func (c *Cleaner) parseOlderThan(olderThan string) (time.Time, error) {
	if olderThan == "" {
		return time.Time{}, nil
	}

	now := time.Now()

	// è§£ææ—¶é—´æ ¼å¼
	if strings.HasSuffix(olderThan, "d") {
		days := strings.TrimSuffix(olderThan, "d")
		var d int
		_, err := fmt.Sscanf(days, "%d", &d)
		if err != nil {
			return time.Time{}, fmt.Errorf("æ— æ•ˆçš„å¤©æ•°æ ¼å¼: %s", olderThan)
		}
		return now.AddDate(0, 0, -d), nil
	}

	if strings.HasSuffix(olderThan, "h") {
		hours := strings.TrimSuffix(olderThan, "h")
		var h int
		_, err := fmt.Sscanf(hours, "%d", &h)
		if err != nil {
			return time.Time{}, fmt.Errorf("æ— æ•ˆçš„å°æ—¶æ ¼å¼: %s", olderThan)
		}
		return now.Add(-time.Duration(h) * time.Hour), nil
	}

	if strings.HasSuffix(olderThan, "m") {
		minutes := strings.TrimSuffix(olderThan, "m")
		var m int
		_, err := fmt.Sscanf(minutes, "%d", &m)
		if err != nil {
			return time.Time{}, fmt.Errorf("æ— æ•ˆçš„åˆ†é’Ÿæ ¼å¼: %s", olderThan)
		}
		return now.Add(-time.Duration(m) * time.Minute), nil
	}

	return time.Time{}, fmt.Errorf("ä¸æ”¯æŒçš„æ—¶é—´æ ¼å¼: %s (æ”¯æŒ: 7d, 24h, 30m)", olderThan)
}

// getImageCacheDir è·å–å›¾ç‰‡ç¼“å­˜ç›®å½•
func (c *Cleaner) getImageCacheDir() string {
	// å°è¯•ä»å›¾ç‰‡é…ç½®è·å–
	if c.imageConfig != nil {
		if cacheDir := c.imageConfig.GetCacheDir(); cacheDir != "" {
			return cacheDir
		}
	}

	// å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
	if cacheDir := os.Getenv("TO_ICALendar_CACHE_DIR"); cacheDir != "" {
		return cacheDir
	}

	// ä½¿ç”¨é»˜è®¤è·¯å¾„
	homeDir, err := os.UserHomeDir()
	if err != nil {
		return ""
	}
	return filepath.Join(homeDir, ".to_icalendar", "cache")
}

// getTempDir è·å–ä¸´æ—¶ç›®å½•
func (c *Cleaner) getTempDir() string {
	// å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
	if tempDir := os.Getenv("TO_ICALendar_TEMP_DIR"); tempDir != "" {
		return tempDir
	}

	// ä½¿ç”¨é»˜è®¤è·¯å¾„
	homeDir, err := os.UserHomeDir()
	if err != nil {
		return ""
	}
	return filepath.Join(homeDir, ".to_icalendar", "temp")
}

// isImageFile æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡æ–‡ä»¶
func (c *Cleaner) isImageFile(path string) bool {
	ext := strings.ToLower(filepath.Ext(path))
	imageExts := []string{".png", ".jpg", ".jpeg", ".gif", ".bmp", ".webp"}
	for _, imgExt := range imageExts {
		if ext == imgExt {
			return true
		}
	}
	return false
}

// isGeneratedFile æ£€æŸ¥æ˜¯å¦ä¸ºç”Ÿæˆçš„æ–‡ä»¶
func (c *Cleaner) isGeneratedFile(path string) bool {
	// æ£€æŸ¥æ–‡ä»¶åæ¨¡å¼
	filename := filepath.Base(path)

	// ä¸´æ—¶ç”Ÿæˆçš„JSONæ–‡ä»¶
	if strings.HasPrefix(filename, "temp_") && strings.HasSuffix(filename, ".json") {
		return true
	}

	// è§£æåç”Ÿæˆçš„æ–‡ä»¶
	if strings.Contains(filename, "_parsed_") && strings.HasSuffix(filename, ".json") {
		return true
	}

	// å…¶ä»–ä¸´æ—¶æ–‡ä»¶æ¨¡å¼
	if strings.HasPrefix(filename, "dify_") && strings.HasSuffix(filename, ".json") {
		return true
	}

	return false
}

// PrintSummary æ‰“å°æ¸…ç†æ‘˜è¦
func (s *CleanSummary) PrintSummary() {
	fmt.Printf("\n=== æ¸…ç†å®Œæˆ ===\n")
	fmt.Printf("æ€»è€—æ—¶: %v\n", s.Duration)
	fmt.Printf("æ¸…ç†æ–‡ä»¶æ•°: %d\n", s.TotalFiles)
	fmt.Printf("é‡Šæ”¾ç©ºé—´: %s\n", formatBytes(s.TotalSize))

	fmt.Printf("\nè¯¦ç»†ç»“æœ:\n")
	for _, result := range s.Results {
		if result.Error != nil {
			fmt.Printf("âŒ %s: %v\n", result.CacheType, result.Error)
			continue
		}

		fmt.Printf("âœ… %s: %dä¸ªæ–‡ä»¶, %s, è€—æ—¶%v\n",
			result.CacheType, result.FilesCount, formatBytes(result.SizeBytes), result.Duration)
	}
}

// PrintPreview æ‰“å°é¢„è§ˆä¿¡æ¯
func (s *CleanSummary) PrintPreview() {
	fmt.Printf("\n=== æ¸…ç†é¢„è§ˆ ===\n")
	fmt.Printf("é¢„è®¡åˆ é™¤æ–‡ä»¶æ•°: %d\n", s.TotalFiles)
	fmt.Printf("é¢„è®¡é‡Šæ”¾ç©ºé—´: %s\n", formatBytes(s.TotalSize))

	fmt.Printf("\nå°†è¦åˆ é™¤çš„æ–‡ä»¶:\n")
	for _, result := range s.Results {
		if result.Error != nil {
			fmt.Printf("âŒ %s: %v\n", result.CacheType, result.Error)
			continue
		}

		fmt.Printf("\nğŸ“ %s (%dä¸ªæ–‡ä»¶, %s):\n",
			result.CacheType, result.FilesCount, formatBytes(result.SizeBytes))

		// æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨ï¼ˆé™åˆ¶æ•°é‡ï¼‰
		maxFiles := 10
		for i, file := range result.Files {
			if i >= maxFiles {
				fmt.Printf("  ... è¿˜æœ‰ %d ä¸ªæ–‡ä»¶\n", len(result.Files)-maxFiles)
				break
			}
			fmt.Printf("  - %s\n", file)
		}
	}

	fmt.Printf("\næ³¨æ„ï¼šè¿™åªæ˜¯é¢„è§ˆï¼Œå®é™…ä¸ä¼šåˆ é™¤ä»»ä½•æ–‡ä»¶ã€‚ä½¿ç”¨ --force å‚æ•°æ‰§è¡Œå®é™…æ¸…ç†ã€‚\n")
}

// formatBytes æ ¼å¼åŒ–å­—èŠ‚æ•°ä¸ºäººç±»å¯è¯»æ ¼å¼
func formatBytes(bytes int64) string {
	const unit = 1024
	if bytes < unit {
		return fmt.Sprintf("%d B", bytes)
	}
	div, exp := int64(unit), 0
	for n := bytes / unit; n >= unit; n /= unit {
		div *= unit
		exp++
	}
	return fmt.Sprintf("%.1f %cB", float64(bytes)/float64(div), "KMGTPE"[exp])
}